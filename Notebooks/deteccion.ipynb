{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUTZoeGD_VlF"
      },
      "source": [
        "## Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMG03yQz_VlJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import time\n",
        "import supervision as sv\n",
        "from transformers import DetrForObjectDetection, DetrImageProcessor, DetrConfig\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "import torchvision\n",
        "import shapely.geometry as sg\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63LJbS_C_VlL"
      },
      "outputs": [],
      "source": [
        "from pytorch_lightning import Trainer\n",
        "import pytorch_lightning as pl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGWg-UG6_VlL"
      },
      "source": [
        "## Data\n",
        "\n",
        "We take the data and annotations, whose only label is \"lesion\", and train a valid DETR model to detect them.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3cuMsdL_VlM"
      },
      "outputs": [],
      "source": [
        "TYPE=\"_Balanced\"\n",
        "#TYPE=\"\"\n",
        "\n",
        "ANNOTATION_FILE_NAME = \"annotation_uniclass.json\"\n",
        "\n",
        "if 'uniclass' in ANNOTATION_FILE_NAME:\n",
        "    MODEL_PATH = 'DETR-uniclass'\n",
        "else:\n",
        "    MODEL_PATH = 'DETR'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TT5y8_S5_VlM",
        "outputId": "11deab6b-5b94-41ab-c8f9-bb6bbcd34e77"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Number of training examples: 1605\n",
            "Number of validation examples: 810\n",
            "Number of test examples: 107\n"
          ]
        }
      ],
      "source": [
        "dataset = './Procesado'+TYPE+'/'\n",
        "\n",
        "TRAIN_DIRECTORY = os.path.join(dataset, \"train/images/\")\n",
        "VAL_DIRECTORY = os.path.join(dataset, \"valid/images/\")\n",
        "TEST_DIRECTORY = os.path.join(dataset, \"test/images/\")\n",
        "\n",
        "class CocoDetection(torchvision.datasets.CocoDetection):\n",
        "    def __init__(\n",
        "        self,\n",
        "        image_directory_path: str,\n",
        "        image_processor,\n",
        "        train: bool = True\n",
        "    ):\n",
        "        annotation_file_path = os.path.join(image_directory_path, ANNOTATION_FILE_NAME)\n",
        "        super(CocoDetection, self).__init__(image_directory_path, annotation_file_path)\n",
        "        self.image_processor = image_processor\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        images, annotations = super(CocoDetection, self).__getitem__(idx)\n",
        "        image_id = self.ids[idx]\n",
        "        annotations = {'image_id': image_id, 'annotations': annotations}\n",
        "        encoding = self.image_processor(images=images, annotations=annotations, return_tensors=\"pt\")\n",
        "        pixel_values = encoding[\"pixel_values\"].squeeze()\n",
        "        target = encoding[\"labels\"][0]\n",
        "\n",
        "        return pixel_values, target\n",
        "\n",
        "image_processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n",
        "TRAIN_DATASET = CocoDetection(image_directory_path=TRAIN_DIRECTORY, image_processor=image_processor, train=True)\n",
        "VAL_DATASET = CocoDetection(image_directory_path=VAL_DIRECTORY, image_processor=image_processor, train=False)\n",
        "TEST_DATASET = CocoDetection(image_directory_path=TEST_DIRECTORY, image_processor=image_processor, train=False)\n",
        "\n",
        "print(\"Number of training examples:\", len(TRAIN_DATASET))\n",
        "print(\"Number of validation examples:\", len(VAL_DATASET))\n",
        "print(\"Number of test examples:\", len(TEST_DATASET))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9PANGZH_VlN"
      },
      "outputs": [],
      "source": [
        "image_ids = TRAIN_DATASET.coco.getImgIds()\n",
        "image_id = random.choice(image_ids)\n",
        "print('Image #{}'.format(image_id))\n",
        "\n",
        "# load image and annotatons\n",
        "image = TRAIN_DATASET.coco.loadImgs(image_id)[0]\n",
        "annotations = TRAIN_DATASET.coco.imgToAnns[image_id]\n",
        "image_path = os.path.join(TRAIN_DATASET.root, image['file_name'])\n",
        "image_path = os.path.join(TRAIN_DATASET.root, image['file_name'])\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# annotate\n",
        "detections = sv.Detections.from_coco_annotations(coco_annotation=annotations)\n",
        "\n",
        "# we will use id2label function for training\n",
        "categories = TRAIN_DATASET.coco.cats\n",
        "id2label = {k: v['name'] for k,v in categories.items()}\n",
        "\n",
        "labels = [\n",
        "    f\"{id2label[class_id]}\"\n",
        "    for _, _, class_id, _\n",
        "    in detections\n",
        "]\n",
        "\n",
        "box_annotator = sv.BoxAnnotator()\n",
        "frame = box_annotator.annotate(scene=image, detections=detections, labels=labels)\n",
        "\n",
        "%matplotlib inline\n",
        "sv.show_frame_in_notebook(image, (8, 8))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apmnHdn6_VlO"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBj-jJG8_VlO"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    pixel_values = [item[0] for item in batch]\n",
        "    encoding = image_processor.pad(pixel_values, return_tensors=\"pt\")\n",
        "    labels = [item[1] for item in batch]\n",
        "    return {\n",
        "        'pixel_values': encoding['pixel_values'],\n",
        "        'pixel_mask': encoding['pixel_mask'],\n",
        "        'labels': labels\n",
        "    }\n",
        "\n",
        "TRAIN_DATALOADER = DataLoader(dataset=TRAIN_DATASET, collate_fn=collate_fn, batch_size=8, num_workers=16,shuffle=True)\n",
        "VAL_DATALOADER = DataLoader(dataset=VAL_DATASET, collate_fn=collate_fn, batch_size=8, num_workers=16)\n",
        "TEST_DATALOADER = DataLoader(dataset=TEST_DATASET, collate_fn=collate_fn, batch_size=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlj3PA_r_VlP"
      },
      "outputs": [],
      "source": [
        "class Detr(pl.LightningModule):\n",
        "    def __init__(self, lr, lr_backbone, weight_decay):\n",
        "        super().__init__()\n",
        "        # replace COCO classification head with custom head\n",
        "        # we specify the \"no_timm\" variant here to not rely on the timm library\n",
        "        # for the convolutional backbone\n",
        "        self.model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\",\n",
        "                                                             revision=\"no_timm\",\n",
        "                                                             num_labels=len(id2label),\n",
        "                                                             ignore_mismatched_sizes=True)\n",
        "         # see https://github.com/PyTorchLightning/pytorch-lightning/pull/1896\n",
        "        self.lr = lr\n",
        "        self.lr_backbone = lr_backbone\n",
        "        self.weight_decay = weight_decay\n",
        "\n",
        "    def forward(self, pixel_values, pixel_mask):\n",
        "        outputs = self.model(pixel_values=pixel_values, pixel_mask=pixel_mask)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def common_step(self, batch, batch_idx):\n",
        "        pixel_values = batch[\"pixel_values\"]\n",
        "        pixel_mask = batch[\"pixel_mask\"]\n",
        "        labels = [{k: v.to(self.device) for k, v in t.items()} for t in batch[\"labels\"]]\n",
        "\n",
        "        outputs = self.model(pixel_values=pixel_values, pixel_mask=pixel_mask, labels=labels)\n",
        "\n",
        "        loss = outputs.loss\n",
        "        loss_dict = outputs.loss_dict\n",
        "\n",
        "        return loss, loss_dict\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss, loss_dict = self.common_step(batch, batch_idx)\n",
        "        # logs metrics for each training_step,\n",
        "        # and the average across the epoch\n",
        "        self.log(\"training_loss\", loss)\n",
        "        for k,v in loss_dict.items():\n",
        "            self.log(\"train_\" + k, v.item())\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        loss, loss_dict = self.common_step(batch, batch_idx)\n",
        "        self.log(\"validation_loss\", loss)\n",
        "        for k,v in loss_dict.items():\n",
        "            self.log(\"validation_\" + k, v.item())\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        param_dicts = [\n",
        "              {\"params\": [p for n, p in self.named_parameters() if \"backbone\" not in n and p.requires_grad]},\n",
        "              {\n",
        "                  \"params\": [p for n, p in self.named_parameters() if \"backbone\" in n and p.requires_grad],\n",
        "                  \"lr\": self.lr_backbone,\n",
        "              },\n",
        "        ]\n",
        "        optimizer = torch.optim.AdamW(param_dicts, lr=self.lr,\n",
        "                                  weight_decay=self.weight_decay)\n",
        "\n",
        "        return optimizer\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return TRAIN_DATALOADER\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return VAL_DATALOADER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Px3kIqiV_VlP",
        "outputId": "9842f257-5bb0-4aa0-a79f-af6d4fcc235d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DetrForObjectDetection were not initialized from the model checkpoint at facebook/detr-resnet-50 and are newly initialized because the shapes did not match:\n",
            "- class_labels_classifier.weight: found shape torch.Size([92, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
            "- class_labels_classifier.bias: found shape torch.Size([92]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = Detr(lr=1e-4, lr_backbone=1e-5, weight_decay=1e-4)\n",
        "\n",
        "batch = next(iter(TRAIN_DATALOADER))\n",
        "outputs = model(pixel_values=batch['pixel_values'], pixel_mask=batch['pixel_mask'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbI1E9kj_VlQ"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir lightning_logs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kU4t_WI7_VlQ",
        "outputId": "46f63193-f92b-4d19-8fbc-e8a5faa3b55c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(max_steps=10000, gradient_clip_val=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "ade03ea9b0194e8083dcc71aad2e33d0",
            "50d001e8b3364a24a5c8340de71c5017",
            "6fbf696c3d1746768a99e5c87ae97f20",
            "d8b00ce1bd1c4244ab589a6b3bd2b44a",
            "f558dc5b103948a9bbc87ff809e1afed",
            "8a6ceafb25ec4f1386b04e81c8b63ca8",
            "56bd544fabde477b9c8440256d2ee8bb",
            "5f8362ce2bae402d9e60fc3efb314670",
            "ea7dcae3802b489f84b8fadfeb9d209b",
            "ed5fa4de094e40968e02b9da1db0a34d",
            "9e8486fccdfc45b2a21de2cdc2a55675",
            "d6c62206565e4b8693fe64e8a5d5a299",
            "8d04bda1d7714f248f3ff6857ee8adb9",
            "13baa98b91ea4e0aabe12b801548c0c6",
            "e1b6fe24af43411a82558b512b2ff1f4",
            "5667107ee1004526bc4296ab75be549a",
            "0bde20220f494f239e396c16530c6783",
            "c5800bb7ac0b40bfae8c1881fb538700",
            "0d725eaefab64683b0d4dd1fe40bbd4d",
            "b3d8902c83bf4e33988f513f8c4ca05e",
            "904f4b64de6840928cd63f7fd6c5db1c",
            "57b5f097268a4f51820154935ab8a01b",
            "5a384d22f076403486a1d6ff6efb9a18",
            "6217baba77cd414eab8eec759daddb1b",
            "ebc1baca26ac4e1baaa774229cfc39e1",
            "635158d9bdca45258475d6cb59230d1d",
            "dd3a68c36fbe46a0bb377af4eca4a746",
            "05cb64905ac6483a8782c0a8d51a48a5",
            "e93a03eaee174cdd9c6dd228bd807212",
            "35b1cc998d2142abb734b8149ae20379",
            "a42f8b4b742b4874ae1ae751e4663303",
            "cbdebbb3e188456890594741624f82b9",
            "edbfd7bd6dad4895aacbe45aeddc3d11",
            "c258317c4c174d54a9b8d700550f06f9",
            "0a67fa0a1a57462a9e05086e5b0c18d9",
            "0aa7fb81ff9b4aee8c2a82c4aed37047",
            "d98d600f65d643399f0b6ab77665ae8f",
            "a3b2c45063ba4aafbf600cdf3422a5ec",
            "642cda6f829c4be2b7b69fda1d2e2798",
            "f9a3427f5ceb41a58afbf8d235ee7627",
            "470c458d0baf4443be2c53323252fab9",
            "0d54a6c3e347419080d5cdd719269976",
            "52805190ba6d443a9d1a973213e54ff7",
            "c171cdad15464c55a04c055ba4d115e3",
            "f17374726d0844f9adaa3b8c27d9826d",
            "42a773ec14c44ff7b5b8b0619d6b9c57",
            "d7c8247264f1415e8185fdff3a51216b",
            "c9608923d54b4b8ebdd4ea5b8236e43b",
            "78331fd09cef4cb7bb1c4d6c56c9e6db",
            "ad9457acb3664b60aa71bfd9782ab564",
            "fca1dd68ba81476587baf42c3c5e7dae"
          ]
        },
        "id": "6gz-rGv4_VlQ",
        "outputId": "03ce3484-220f-4bbf-e909-04e2790cfddc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "Missing logger folder: /home/eva/Clean_Articulo/lightning_logs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name  | Type                   | Params\n",
            "-------------------------------------------------\n",
            "0 | model | DetrForObjectDetection | 41.5 M\n",
            "-------------------------------------------------\n",
            "18.0 M    Trainable params\n",
            "23.5 M    Non-trainable params\n",
            "41.5 M    Total params\n",
            "166.007   Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ade03ea9b0194e8083dcc71aad2e33d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: |                                                                      | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/eva/anaconda3/lib/python3.9/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 8. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50d001e8b3364a24a5c8340de71c5017",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |                                                                             | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6fbf696c3d1746768a99e5c87ae97f20",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/eva/anaconda3/lib/python3.9/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8b00ce1bd1c4244ab589a6b3bd2b44a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f558dc5b103948a9bbc87ff809e1afed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a6ceafb25ec4f1386b04e81c8b63ca8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56bd544fabde477b9c8440256d2ee8bb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f8362ce2bae402d9e60fc3efb314670",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea7dcae3802b489f84b8fadfeb9d209b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed5fa4de094e40968e02b9da1db0a34d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e8486fccdfc45b2a21de2cdc2a55675",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6c62206565e4b8693fe64e8a5d5a299",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d04bda1d7714f248f3ff6857ee8adb9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13baa98b91ea4e0aabe12b801548c0c6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1b6fe24af43411a82558b512b2ff1f4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5667107ee1004526bc4296ab75be549a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0bde20220f494f239e396c16530c6783",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c5800bb7ac0b40bfae8c1881fb538700",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d725eaefab64683b0d4dd1fe40bbd4d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3d8902c83bf4e33988f513f8c4ca05e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "904f4b64de6840928cd63f7fd6c5db1c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "57b5f097268a4f51820154935ab8a01b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a384d22f076403486a1d6ff6efb9a18",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6217baba77cd414eab8eec759daddb1b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ebc1baca26ac4e1baaa774229cfc39e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "635158d9bdca45258475d6cb59230d1d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd3a68c36fbe46a0bb377af4eca4a746",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05cb64905ac6483a8782c0a8d51a48a5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e93a03eaee174cdd9c6dd228bd807212",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35b1cc998d2142abb734b8149ae20379",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a42f8b4b742b4874ae1ae751e4663303",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cbdebbb3e188456890594741624f82b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "edbfd7bd6dad4895aacbe45aeddc3d11",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c258317c4c174d54a9b8d700550f06f9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a67fa0a1a57462a9e05086e5b0c18d9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0aa7fb81ff9b4aee8c2a82c4aed37047",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d98d600f65d643399f0b6ab77665ae8f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3b2c45063ba4aafbf600cdf3422a5ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "642cda6f829c4be2b7b69fda1d2e2798",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f9a3427f5ceb41a58afbf8d235ee7627",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "470c458d0baf4443be2c53323252fab9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d54a6c3e347419080d5cdd719269976",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52805190ba6d443a9d1a973213e54ff7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c171cdad15464c55a04c055ba4d115e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f17374726d0844f9adaa3b8c27d9826d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42a773ec14c44ff7b5b8b0619d6b9c57",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7c8247264f1415e8185fdff3a51216b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c9608923d54b4b8ebdd4ea5b8236e43b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "78331fd09cef4cb7bb1c4d6c56c9e6db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad9457acb3664b60aa71bfd9782ab564",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fca1dd68ba81476587baf42c3c5e7dae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                           | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_steps=10000` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entrenamiento time(min.):  86.0\n",
            "472030:28:25\n"
          ]
        }
      ],
      "source": [
        "inicio = time.time()\n",
        "trainer.fit(model)\n",
        "print(\"Entrenamiento time(min.): \", round((time.time()-inicio)/60,0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHJvOIUT_VlR"
      },
      "outputs": [],
      "source": [
        "model.model.save_pretrained('./DETR_Results/'+MODEL_PATH+TYPE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELt2TtSR_VlR",
        "outputId": "73f0e4f5-812a-41fd-e2ac-caad40e33b8e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DetrForObjectDetection(\n",
              "  (model): DetrModel(\n",
              "    (backbone): DetrConvModel(\n",
              "      (conv_encoder): DetrConvEncoder(\n",
              "        (model): ResNetBackbone(\n",
              "          (embedder): ResNetEmbeddings(\n",
              "            (embedder): ResNetConvLayer(\n",
              "              (convolution): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "              (normalization): DetrFrozenBatchNorm2d()\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (pooler): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "          )\n",
              "          (encoder): ResNetEncoder(\n",
              "            (stages): ModuleList(\n",
              "              (0): ResNetStage(\n",
              "                (layers): Sequential(\n",
              "                  (0): ResNetBottleNeckLayer(\n",
              "                    (shortcut): ResNetShortCut(\n",
              "                      (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                      (normalization): DetrFrozenBatchNorm2d()\n",
              "                    )\n",
              "                    (layer): Sequential(\n",
              "                      (0): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): ReLU()\n",
              "                      )\n",
              "                      (1): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): ReLU()\n",
              "                      )\n",
              "                      (2): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): Identity()\n",
              "                      )\n",
              "                    )\n",
              "                    (activation): ReLU()\n",
              "                  )\n",
              "                  (1): ResNetBottleNeckLayer(\n",
              "                    (shortcut): Identity()\n",
              "                    (layer): Sequential(\n",
              "                      (0): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): ReLU()\n",
              "                      )\n",
              "                      (1): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): ReLU()\n",
              "                      )\n",
              "                      (2): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): Identity()\n",
              "                      )\n",
              "                    )\n",
              "                    (activation): ReLU()\n",
              "                  )\n",
              "                  (2): ResNetBottleNeckLayer(\n",
              "                    (shortcut): Identity()\n",
              "                    (layer): Sequential(\n",
              "                      (0): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): ReLU()\n",
              "                      )\n",
              "                      (1): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): ReLU()\n",
              "                      )\n",
              "                      (2): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): Identity()\n",
              "                      )\n",
              "                    )\n",
              "                    (activation): ReLU()\n",
              "                  )\n",
              "                )\n",
              "              )\n",
              "              (1): ResNetStage(\n",
              "                (layers): Sequential(\n",
              "                  (0): ResNetBottleNeckLayer(\n",
              "                    (shortcut): ResNetShortCut(\n",
              "                      (convolution): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "                      (normalization): DetrFrozenBatchNorm2d()\n",
              "                    )\n",
              "                    (layer): Sequential(\n",
              "                      (0): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): ReLU()\n",
              "                      )\n",
              "                      (1): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): ReLU()\n",
              "                      )\n",
              "                      (2): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): Identity()\n",
              "                      )\n",
              "                    )\n",
              "                    (activation): ReLU()\n",
              "                  )\n",
              "                  (1): ResNetBottleNeckLayer(\n",
              "                    (shortcut): Identity()\n",
              "                    (layer): Sequential(\n",
              "                      (0): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): ReLU()\n",
              "                      )\n",
              "                      (1): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): ReLU()\n",
              "                      )\n",
              "                      (2): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): Identity()\n",
              "                      )\n",
              "                    )\n",
              "                    (activation): ReLU()\n",
              "                  )\n",
              "                  (2): ResNetBottleNeckLayer(\n",
              "                    (shortcut): Identity()\n",
              "                    (layer): Sequential(\n",
              "                      (0): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): ReLU()\n",
              "                      )\n",
              "                      (1): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): ReLU()\n",
              "                      )\n",
              "                      (2): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): Identity()\n",
              "                      )\n",
              "                    )\n",
              "                    (activation): ReLU()\n",
              "                  )\n",
              "                  (3): ResNetBottleNeckLayer(\n",
              "                    (shortcut): Identity()\n",
              "                    (layer): Sequential(\n",
              "                      (0): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): ReLU()\n",
              "                      )\n",
              "                      (1): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): ReLU()\n",
              "                      )\n",
              "                      (2): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): Identity()\n",
              "                      )\n",
              "                    )\n",
              "                    (activation): ReLU()\n",
              "                  )\n",
              "                )\n",
              "              )\n",
              "              (2): ResNetStage(\n",
              "                (layers): Sequential(\n",
              "                  (0): ResNetBottleNeckLayer(\n",
              "                    (shortcut): ResNetShortCut(\n",
              "                      (convolution): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "                      (normalization): DetrFrozenBatchNorm2d()\n",
              "                    )\n",
              "                    (layer): Sequential(\n",
              "                      (0): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): ReLU()\n",
              "                      )\n",
              "                      (1): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): ReLU()\n",
              "                      )\n",
              "                      (2): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): Identity()\n",
              "                      )\n",
              "                    )\n",
              "                    (activation): ReLU()\n",
              "                  )\n",
              "                  (1): ResNetBottleNeckLayer(\n",
              "                    (shortcut): Identity()\n",
              "                    (layer): Sequential(\n",
              "                      (0): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): ReLU()\n",
              "                      )\n",
              "                      (1): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): ReLU()\n",
              "                      )\n",
              "                      (2): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): Identity()\n",
              "                      )\n",
              "                    )\n",
              "                    (activation): ReLU()\n",
              "                  )\n",
              "                  (2): ResNetBottleNeckLayer(\n",
              "                    (shortcut): Identity()\n",
              "                    (layer): Sequential(\n",
              "                      (0): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): ReLU()\n",
              "                      )\n",
              "                      (1): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): ReLU()\n",
              "                      )\n",
              "                      (2): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): Identity()\n",
              "                      )\n",
              "                    )\n",
              "                    (activation): ReLU()\n",
              "                  )\n",
              "                  (3): ResNetBottleNeckLayer(\n",
              "                    (shortcut): Identity()\n",
              "                    (layer): Sequential(\n",
              "                      (0): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): ReLU()\n",
              "                      )\n",
              "                      (1): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): ReLU()\n",
              "                      )\n",
              "                      (2): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): Identity()\n",
              "                      )\n",
              "                    )\n",
              "                    (activation): ReLU()\n",
              "                  )\n",
              "                  (4): ResNetBottleNeckLayer(\n",
              "                    (shortcut): Identity()\n",
              "                    (layer): Sequential(\n",
              "                      (0): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): ReLU()\n",
              "                      )\n",
              "                      (1): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): ReLU()\n",
              "                      )\n",
              "                      (2): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): Identity()\n",
              "                      )\n",
              "                    )\n",
              "                    (activation): ReLU()\n",
              "                  )\n",
              "                  (5): ResNetBottleNeckLayer(\n",
              "                    (shortcut): Identity()\n",
              "                    (layer): Sequential(\n",
              "                      (0): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): ReLU()\n",
              "                      )\n",
              "                      (1): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): ReLU()\n",
              "                      )\n",
              "                      (2): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): Identity()\n",
              "                      )\n",
              "                    )\n",
              "                    (activation): ReLU()\n",
              "                  )\n",
              "                )\n",
              "              )\n",
              "              (3): ResNetStage(\n",
              "                (layers): Sequential(\n",
              "                  (0): ResNetBottleNeckLayer(\n",
              "                    (shortcut): ResNetShortCut(\n",
              "                      (convolution): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "                      (normalization): DetrFrozenBatchNorm2d()\n",
              "                    )\n",
              "                    (layer): Sequential(\n",
              "                      (0): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): ReLU()\n",
              "                      )\n",
              "                      (1): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): ReLU()\n",
              "                      )\n",
              "                      (2): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): Identity()\n",
              "                      )\n",
              "                    )\n",
              "                    (activation): ReLU()\n",
              "                  )\n",
              "                  (1): ResNetBottleNeckLayer(\n",
              "                    (shortcut): Identity()\n",
              "                    (layer): Sequential(\n",
              "                      (0): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): ReLU()\n",
              "                      )\n",
              "                      (1): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): ReLU()\n",
              "                      )\n",
              "                      (2): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): Identity()\n",
              "                      )\n",
              "                    )\n",
              "                    (activation): ReLU()\n",
              "                  )\n",
              "                  (2): ResNetBottleNeckLayer(\n",
              "                    (shortcut): Identity()\n",
              "                    (layer): Sequential(\n",
              "                      (0): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): ReLU()\n",
              "                      )\n",
              "                      (1): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): ReLU()\n",
              "                      )\n",
              "                      (2): ResNetConvLayer(\n",
              "                        (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                        (normalization): DetrFrozenBatchNorm2d()\n",
              "                        (activation): Identity()\n",
              "                      )\n",
              "                    )\n",
              "                    (activation): ReLU()\n",
              "                  )\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (position_embedding): DetrSinePositionEmbedding()\n",
              "    )\n",
              "    (input_projection): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (query_position_embeddings): Embedding(100, 256)\n",
              "    (encoder): DetrEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x DetrEncoderLayer(\n",
              "          (self_attn): DetrAttention(\n",
              "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): ReLU()\n",
              "          (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
              "          (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
              "          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (decoder): DetrDecoder(\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x DetrDecoderLayer(\n",
              "          (self_attn): DetrAttention(\n",
              "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (activation_fn): ReLU()\n",
              "          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): DetrAttention(\n",
              "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
              "          (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
              "          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (class_labels_classifier): Linear(in_features=256, out_features=2, bias=True)\n",
              "  (bbox_predictor): DetrMLPPredictionHead(\n",
              "    (layers): ModuleList(\n",
              "      (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
              "      (2): Linear(in_features=256, out_features=4, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# loading model\n",
        "model = DetrForObjectDetection.from_pretrained('./DETR_Results/'+MODEL_PATH+TYPE)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hflNcNZ_VlR"
      },
      "outputs": [],
      "source": [
        "def calculate_iou_matrix(boxes_true, boxes_pred):\n",
        "    iou_matrix = np.zeros((len(boxes_true), len(boxes_pred)))\n",
        "    i=1\n",
        "    for i, box_true in enumerate(boxes_true):\n",
        "        y_true = sg.box(boxes_true[0], boxes_true[1], boxes_true[0] + boxes_true[2], boxes_true[1] + boxes_true[3])\n",
        "        for j, box_pred in enumerate(boxes_pred):\n",
        "            x_pred, y_pred, xx_pred, yy_pred = box_pred\n",
        "            y_pred2 = sg.box(x_pred, y_pred, xx_pred, yy_pred)\n",
        "            intersection_area = y_true.intersection(y_pred2).area\n",
        "            union_area = y_true.union(y_pred2).area\n",
        "            iou = intersection_area / union_area\n",
        "            iou_matrix[i, j] = iou\n",
        "    return iou_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "WLEctR_O_VlR"
      },
      "outputs": [],
      "source": [
        "random.seed(123)\n",
        "CONFIDENCE_TRESHOLD = 0.1\n",
        "# utils\n",
        "categories = TEST_DATASET.coco.cats\n",
        "id2label = {k: v['name'] for k,v in categories.items()}\n",
        "box_annotator = sv.BoxAnnotator()\n",
        "\n",
        "# select random image\n",
        "image_ids = TEST_DATASET.coco.getImgIds()\n",
        "image_id = random.choice(image_ids)\n",
        "print('Image #{}'.format(image_id))\n",
        "\n",
        "# load image and annotatons\n",
        "image = TEST_DATASET.coco.loadImgs(image_id)[0]\n",
        "annotations = TEST_DATASET.coco.imgToAnns[image_id]\n",
        "image_path = os.path.join(TEST_DATASET.root, image['file_name'])\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Annotate ground truth\n",
        "gt_detections = sv.Detections.from_coco_annotations(coco_annotation=annotations)\n",
        "labels = [f\"{id2label[class_id]}\" for _, _, class_id, _ in gt_detections]\n",
        "frame_ground_truth = box_annotator.annotate(scene=image.copy(), detections=gt_detections, labels=labels)\n",
        "\n",
        "true_boxes=annotations[0]['bbox']\n",
        "\n",
        "# Annotate detections\n",
        "with torch.no_grad():\n",
        "\n",
        "    # load image and predict\n",
        "    inputs = image_processor(images=image, return_tensors='pt').to(device)\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    # post-process\n",
        "    target_sizes = torch.tensor([image.shape[:2]]).to(device)\n",
        "    results = image_processor.post_process_object_detection(\n",
        "        outputs=outputs,\n",
        "        threshold=CONFIDENCE_TRESHOLD,\n",
        "        target_sizes=target_sizes\n",
        "    )[0]\n",
        "\n",
        "    if len(results['boxes']) != 0:\n",
        "        pred_boxes = results['boxes'].cpu().data.numpy().astype(np.float16)\n",
        "        scores = results['scores'].cpu().data.numpy()\n",
        "\n",
        "        iou = calculate_iou_matrix(true_boxes,pred_boxes)\n",
        "        iou_max = np.argmax(iou[0])\n",
        "        print(iou[0])\n",
        "        print('IoU: ',round(iou[0][iou_max],3))\n",
        "        best_result={'scores':torch.tensor([results['scores'][iou_max].item()],device='cuda:0'),\n",
        "                     'labels':torch.tensor([results['labels'][iou_max].item()], device='cuda:0'),\n",
        "                     'boxes' :torch.tensor([results['boxes'][iou_max].tolist()], device='cuda:0')}\n",
        "        detections = sv.Detections.from_transformers(transformers_results=best_result)\n",
        "        labels = [f\"{id2label[class_id]} {confidence:.2f}\" for _, confidence, class_id, _ in detections]\n",
        "        frame_detections = box_annotator.annotate(scene=image.copy(), detections=detections, labels=labels)\n",
        "\n",
        "        # Combine both images side by side and display\n",
        "        fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
        "        axs[0].imshow(cv2.cvtColor(frame_ground_truth, cv2.COLOR_BGR2RGB))\n",
        "        axs[0].axis('off')\n",
        "        axs[0].set_title('Ground Truth')\n",
        "\n",
        "        axs[1].imshow(cv2.cvtColor(frame_detections, cv2.COLOR_BGR2RGB))\n",
        "        axs[1].axis('off')\n",
        "        axs[1].set_title('Detections')\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"Sin deteteccin...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8tMNfWs_VlS"
      },
      "source": [
        "## Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56is5VOO_VlS"
      },
      "outputs": [],
      "source": [
        "#Save the bbox test predictions\n",
        "try:\n",
        "    os.makedirs('./data'+TYPE+'/DETR') #For ViT\n",
        "    os.makedirs('./data'+TYPE+'/DETR/test')\n",
        "    os.makedirs('./data'+TYPE+'/DETR/test/Cncer')\n",
        "    os.makedirs('./data'+TYPE+'/DETR/test/Control')\n",
        "    os.makedirs('./Procesado'+TYPE+'/test/DETR') #For SAM\n",
        "except OSError as e:\n",
        "    if e.errno != errno.EEXIST:\n",
        "        raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgxbrgEQ_VlS",
        "outputId": "b4e2a82a-bb56-4180-eafd-6cebb166e823"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|                                                        | 23/107 [01:34<05:44,  4.11s/it]/home/eva/anaconda3/lib/python3.9/site-packages/shapely/set_operations.py:133: RuntimeWarning: invalid value encountered in intersection\n",
            "  return lib.intersection(a, b, **kwargs)\n",
            "100%|| 107/107 [07:18<00:00,  4.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TEST PREDICTIONS COMPLETE\n",
            "*****END*****\n",
            "Tiempo de ejecucin:  7.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "random.seed(123)\n",
        "inicio=time.time()\n",
        "\n",
        "CONFIDENCE_TRESHOLD = 0.1\n",
        "\n",
        "writepredsdetectDict = [] # Dict Results\n",
        "\n",
        "categories = TEST_DATASET.coco.cats\n",
        "id2label = {k: v['name'] for k,v in categories.items()}\n",
        "box_annotator = sv.BoxAnnotator()\n",
        "image_ids = TEST_DATASET.coco.getImgIds()\n",
        "\n",
        "for image_id in tqdm(image_ids):\n",
        "    # load image and annotatons\n",
        "    image = TEST_DATASET.coco.loadImgs(image_id)[0]\n",
        "    annotations = TEST_DATASET.coco.imgToAnns[image_id]\n",
        "    image_name=image['file_name']\n",
        "    image_path = os.path.join(TEST_DATASET.root, image['file_name'])\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Annotate ground truth\n",
        "    gt_detections = sv.Detections.from_coco_annotations(coco_annotation=annotations)\n",
        "    gt_labels = [f\"{id2label[class_id]}\" for _, _, class_id, _ in gt_detections]\n",
        "    true_boxes=annotations[0]['bbox']\n",
        "\n",
        "    # Annotate detections\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # load image and predict\n",
        "        inputs = image_processor(images=image, return_tensors='pt').to(device)\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # post-process\n",
        "    target_sizes = torch.tensor([image.shape[:2]]).to(device)\n",
        "    results = image_processor.post_process_object_detection(outputs=outputs,\n",
        "                                                            threshold=CONFIDENCE_TRESHOLD,\n",
        "                                                            target_sizes=target_sizes)[0]\n",
        "\n",
        "    if len(results['boxes']) != 0:\n",
        "        pred_boxes = results['boxes'].cpu().data.numpy().astype(np.float16)\n",
        "        scores = results['scores'].cpu().data.numpy()\n",
        "\n",
        "        iou = calculate_iou_matrix(true_boxes,pred_boxes)[0]\n",
        "        iou_max = np.argmax(iou)\n",
        "\n",
        "        best_result={'scores':torch.tensor([results['scores'][iou_max].item()],device='cuda:0'),\n",
        "                         'labels':torch.tensor([results['labels'][iou_max].item()], device='cuda:0'),\n",
        "                         'boxes' :torch.tensor([results['boxes'][iou_max].tolist()], device='cuda:0')}\n",
        "        detections = sv.Detections.from_transformers(transformers_results=best_result)\n",
        "        labels = [f\"{id2label[class_id]} {confidence:.2f}\" for _, confidence, class_id, _ in detections]\n",
        "\n",
        "        #---------We save the result for segmentation---------\n",
        "        #We cut ROI\n",
        "        bbox=results['boxes'][iou_max].tolist()\n",
        "        orig_image=image.copy()\n",
        "        my_mask=np.zeros((orig_image.shape[0],orig_image.shape[1]),dtype=np.uint8)\n",
        "        my_mask[int(bbox[1]):int(bbox[3]),int(bbox[0]):int(bbox[2])]=255\n",
        "        my_mask=cv2.cvtColor(my_mask, cv2.COLOR_GRAY2BGR)\n",
        "        # Apply the mask to the image\n",
        "        result = cv2.bitwise_and(orig_image, my_mask)\n",
        "\n",
        "        if 'C' in image_name:\n",
        "            new_dir='./data'+TYPE+'/DETR/test/Cncer/'\n",
        "        else:\n",
        "            new_dir='./data'+TYPE+'/DETR/test/Control/'\n",
        "        cv2.imwrite(new_dir+str(image_name), result)\n",
        "        time.sleep(2)\n",
        "        cv2.imwrite('./Procesado'+TYPE+'/test/DETR/'+str(image_name), result)\n",
        "        time.sleep(2)\n",
        "\n",
        "        writepredsdetectDict.append({'modelo':MODEL_PATH,\n",
        "                                             'imagen':image_name,\n",
        "                                             'set':'Test',\n",
        "                                             'clase':gt_labels,\n",
        "                                             'true_box':true_boxes,\n",
        "                                             'predicion':bbox,\n",
        "                                             'IoU': round(iou[iou_max],3),\n",
        "                                             'etiqueta':labels,\n",
        "                                             'score':round(results['scores'][iou_max].item(),3)\n",
        "                                    })\n",
        "    else:\n",
        "        orig_image=image.copy()\n",
        "        if 'C' in image_name:\n",
        "            new_dir='./data'+TYPE+'/DETR/test/Cncer/'\n",
        "        else:\n",
        "            new_dir='./data'+TYPE+'/DETR/test/Control/'\n",
        "\n",
        "        cv2.imwrite(new_dir+str(image_name), orig_image)\n",
        "        time.sleep(2)\n",
        "        cv2.imwrite('./Procesado'+TYPE+'/test/DETR/'+str(image_name), orig_image)\n",
        "        time.sleep(2)\n",
        "        #-----------We store data---------\n",
        "        writepredsdetectDict.append({'modelo':MODEL_PATH,\n",
        "                                        'imagen':image_name,\n",
        "                                        'set':'Test',\n",
        "                                        'clase':gt_labels,\n",
        "                                        'true_box':true_boxes,\n",
        "                                        'predicion':None,\n",
        "                                        'IoU': None,\n",
        "                                        'etiqueta':None,\n",
        "                                        'score':None})\n",
        "print('TEST PREDICTIONS COMPLETE')\n",
        "\n",
        "#-------We proceed to store the results in file\n",
        "file_name='resultados.csv'\n",
        "archivo='./data'+TYPE+'/DETR/'+file_name\n",
        "if os.path.isfile(archivo):\n",
        "    modo = 'a+'\n",
        "else:\n",
        "    modo = 'w'\n",
        "with open(archivo, modo, newline='') as csvfile:\n",
        "    fieldnames = ['modelo', 'imagen','set', 'clase','true_box','predicion','IoU','etiqueta','score']\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "    if modo=='w':\n",
        "        writer.writeheader()\n",
        "    for d in writepredsdetectDict:\n",
        "        writer.writerow(d)\n",
        "print('*****END*****')\n",
        "print('Tiempo de ejecucin: ',round((time.time()-inicio)/60,0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2t_h72sR_VlT"
      },
      "outputs": [],
      "source": [
        "#To save valid predictions\n",
        "try:\n",
        "    os.makedirs('./data'+TYPE+'/DETR/valid')\n",
        "    os.makedirs('./data'+TYPE+'/DETR/valid/Cncer')\n",
        "    os.makedirs('./data'+TYPE+'/DETR/valid/Control')\n",
        "    os.makedirs('./Procesado'+TYPE+'/valid/DETR')\n",
        "except OSError as e:\n",
        "    if e.errno != errno.EEXIST:\n",
        "        raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GU3mqX3e_VlT",
        "outputId": "a08cb3c3-36ca-439a-d54e-10a1bcd7120e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 810/810 [55:15<00:00,  4.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VALID PREDICTIONS COMPLETE\n",
            "*****END*****\n",
            "Tiempo de ejecucin:  55.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "random.seed(123)\n",
        "inicio=time.time()\n",
        "\n",
        "CONFIDENCE_TRESHOLD = 0.1\n",
        "\n",
        "writepredsdetectDict = [] # Dict Results\n",
        "\n",
        "categories = VAL_DATASET.coco.cats\n",
        "id2label = {k: v['name'] for k,v in categories.items()}\n",
        "box_annotator = sv.BoxAnnotator()\n",
        "image_ids = VAL_DATASET.coco.getImgIds()\n",
        "\n",
        "for image_id in tqdm(image_ids):\n",
        "    # load image and annotatons\n",
        "    image = VAL_DATASET.coco.loadImgs(image_id)[0]\n",
        "    annotations = VAL_DATASET.coco.imgToAnns[image_id]\n",
        "    image_name=image['file_name']\n",
        "    image_path = os.path.join(VAL_DATASET.root, image['file_name'])\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Annotate ground truth\n",
        "    gt_detections = sv.Detections.from_coco_annotations(coco_annotation=annotations)\n",
        "    gt_labels = [f\"{id2label[class_id]}\" for _, _, class_id, _ in gt_detections]\n",
        "    true_boxes=annotations[0]['bbox']\n",
        "\n",
        "    # Annotate detections\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # load image and predict\n",
        "        inputs = image_processor(images=image, return_tensors='pt').to(device)\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # post-process\n",
        "    target_sizes = torch.tensor([image.shape[:2]]).to(device)\n",
        "    results = image_processor.post_process_object_detection(outputs=outputs,\n",
        "                                                            threshold=CONFIDENCE_TRESHOLD,\n",
        "                                                            target_sizes=target_sizes)[0]\n",
        "\n",
        "    if len(results['boxes']) != 0:\n",
        "        pred_boxes = results['boxes'].cpu().data.numpy().astype(np.float16)\n",
        "        scores = results['scores'].cpu().data.numpy()\n",
        "\n",
        "        iou = calculate_iou_matrix(true_boxes,pred_boxes)[0]\n",
        "        iou_max = np.argmax(iou)\n",
        "\n",
        "        best_result={'scores':torch.tensor([results['scores'][iou_max].item()],device='cuda:0'),\n",
        "                         'labels':torch.tensor([results['labels'][iou_max].item()], device='cuda:0'),\n",
        "                         'boxes' :torch.tensor([results['boxes'][iou_max].tolist()], device='cuda:0')}\n",
        "        detections = sv.Detections.from_transformers(transformers_results=best_result)\n",
        "        labels = [f\"{id2label[class_id]} {confidence:.2f}\" for _, confidence, class_id, _ in detections]\n",
        "\n",
        "        #---------We save the result for segmentation---------\n",
        "        # We cut ROI\n",
        "        bbox=results['boxes'][iou_max].tolist()\n",
        "        orig_image=image.copy()\n",
        "        my_mask=np.zeros((orig_image.shape[0],orig_image.shape[1]),dtype=np.uint8)\n",
        "        my_mask[int(bbox[1]):int(bbox[3]),int(bbox[0]):int(bbox[2])]=255\n",
        "        my_mask=cv2.cvtColor(my_mask, cv2.COLOR_GRAY2BGR)\n",
        "        # Apply the mask to the image\n",
        "        result = cv2.bitwise_and(orig_image, my_mask)\n",
        "\n",
        "        if 'C' in image_name:\n",
        "            new_dir='./data'+TYPE+'/DETR/valid/Cncer/'\n",
        "        else:\n",
        "            new_dir='./data'+TYPE+'/DETR/valid/Control/'\n",
        "        cv2.imwrite(new_dir+str(image_name), result)\n",
        "        time.sleep(2)\n",
        "        cv2.imwrite('./Procesado'+TYPE+'/valid/DETR/'+str(image_name), result)\n",
        "        time.sleep(2)\n",
        "\n",
        "        writepredsdetectDict.append({'modelo':MODEL_PATH,\n",
        "                                             'imagen':str(image_name),\n",
        "                                             'set':'Valid',\n",
        "                                             'clase':gt_labels,\n",
        "                                             'true_box':true_boxes,\n",
        "                                             'predicion':bbox,\n",
        "                                             'IoU': round(iou[iou_max],3),\n",
        "                                             'etiqueta':labels,\n",
        "                                             'score':round(results['scores'][iou_max].item(),3)\n",
        "                                    })\n",
        "    else:\n",
        "        orig_image=image.copy()\n",
        "        if 'C' in image_name:\n",
        "            new_dir='./data'+TYPE+'/DETR/valid/Cncer/'\n",
        "        else:\n",
        "            new_dir='./data'+TYPE+'/DETR/valid/Control/'\n",
        "\n",
        "        cv2.imwrite(new_dir+str(image_name), orig_image)\n",
        "        time.sleep(2)\n",
        "        cv2.imwrite('./Procesado'+TYPE+'/valid/DETR/'+str(image_name), orig_image)\n",
        "        time.sleep(2)\n",
        "        #-----------We store data---------\n",
        "        writepredsdetectDict.append({'modelo':MODEL_PATH,\n",
        "                                        'imagen':str(image_name),\n",
        "                                        'set':'Valid',\n",
        "                                        'clase':gt_labels,\n",
        "                                        'true_box':true_boxes,\n",
        "                                        'predicion':None,\n",
        "                                        'IoU': None,\n",
        "                                        'etiqueta':None,\n",
        "                                        'score':None})\n",
        "print('VALID PREDICTIONS COMPLETE')\n",
        "\n",
        "#-------We proceed to store the results in file\n",
        "file_name='resultados.csv'\n",
        "archivo='./data'+TYPE+'/DETR/'+file_name\n",
        "if os.path.isfile(archivo):\n",
        "    modo = 'a+'\n",
        "else:\n",
        "    modo = 'w'\n",
        "with open(archivo, modo, newline='') as csvfile:\n",
        "    fieldnames = ['modelo', 'imagen','set', 'clase','true_box','predicion','IoU','etiqueta','score']\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "    if modo=='w':\n",
        "        writer.writeheader()\n",
        "    for d in writepredsdetectDict:\n",
        "        writer.writerow(d)\n",
        "print('*****END*****')\n",
        "print('Tiempo de ejecucin: ',round((time.time()-inicio)/60,0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6z13NnOt_VlT"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    os.makedirs('./data'+TYPE+'/DETR/train')\n",
        "    os.makedirs('./data'+TYPE+'/DETR/train/Cncer')\n",
        "    os.makedirs('./data'+TYPE+'/DETR/train/Control')\n",
        "    os.makedirs('./Procesado'+TYPE+'/train/DETR')\n",
        "except OSError as e:\n",
        "    if e.errno != errno.EEXIST:\n",
        "        raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bFKREjp_VlT",
        "outputId": "85e6d22c-064d-4f4b-80ad-e8c01b06ba1c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1605/1605 [1:49:26<00:00,  4.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TRAIN PREDICTIONS COMPLETE\n",
            "*****END*****\n",
            "Tiempo de ejecucin:  109.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "random.seed(123)\n",
        "inicio=time.time()\n",
        "\n",
        "CONFIDENCE_TRESHOLD = 0.1\n",
        "\n",
        "writepredsdetectDict = [] # Dict Results\n",
        "\n",
        "categories = TRAIN_DATASET.coco.cats\n",
        "id2label = {k: v['name'] for k,v in categories.items()}\n",
        "box_annotator = sv.BoxAnnotator()\n",
        "image_ids = TRAIN_DATASET.coco.getImgIds()\n",
        "\n",
        "for image_id in tqdm(image_ids):\n",
        "    # load image and annotatons\n",
        "    image = TRAIN_DATASET.coco.loadImgs(image_id)[0]\n",
        "    annotations = TRAIN_DATASET.coco.imgToAnns[image_id]\n",
        "    image_name=image['file_name']\n",
        "    image_path = os.path.join(TRAIN_DATASET.root, image['file_name'])\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Annotate ground truth\n",
        "    gt_detections = sv.Detections.from_coco_annotations(coco_annotation=annotations)\n",
        "    gt_labels = [f\"{id2label[class_id]}\" for _, _, class_id, _ in gt_detections]\n",
        "    true_boxes=annotations[0]['bbox']\n",
        "\n",
        "    # Annotate detections\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # load image and predict\n",
        "        inputs = image_processor(images=image, return_tensors='pt').to(device)\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # post-process\n",
        "    target_sizes = torch.tensor([image.shape[:2]]).to(device)\n",
        "    results = image_processor.post_process_object_detection(outputs=outputs,\n",
        "                                                            threshold=CONFIDENCE_TRESHOLD,\n",
        "                                                            target_sizes=target_sizes)[0]\n",
        "\n",
        "    if len(results['boxes']) != 0:\n",
        "        pred_boxes = results['boxes'].cpu().data.numpy().astype(np.float16)\n",
        "        scores = results['scores'].cpu().data.numpy()\n",
        "\n",
        "        iou = calculate_iou_matrix(true_boxes,pred_boxes)[0]\n",
        "        iou_max = np.argmax(iou)\n",
        "\n",
        "        best_result={'scores':torch.tensor([results['scores'][iou_max].item()],device='cuda:0'),\n",
        "                         'labels':torch.tensor([results['labels'][iou_max].item()], device='cuda:0'),\n",
        "                         'boxes' :torch.tensor([results['boxes'][iou_max].tolist()], device='cuda:0')}\n",
        "        detections = sv.Detections.from_transformers(transformers_results=best_result)\n",
        "        labels = [f\"{id2label[class_id]} {confidence:.2f}\" for _, confidence, class_id, _ in detections]\n",
        "\n",
        "        #-------We save the result for segmentation-------\n",
        "        # We cut ROI\n",
        "        bbox=results['boxes'][iou_max].tolist()\n",
        "        orig_image=image.copy()\n",
        "        my_mask=np.zeros((orig_image.shape[0],orig_image.shape[1]),dtype=np.uint8)\n",
        "        my_mask[int(bbox[1]):int(bbox[3]),int(bbox[0]):int(bbox[2])]=255\n",
        "        my_mask=cv2.cvtColor(my_mask, cv2.COLOR_GRAY2BGR)\n",
        "        # Apply the mask to the image\n",
        "        result = cv2.bitwise_and(orig_image, my_mask)\n",
        "\n",
        "        if 'C' in image_name:\n",
        "            new_dir='./data'+TYPE+'/DETR/train/Cncer/'\n",
        "        else:\n",
        "            new_dir='./data'+TYPE+'/DETR/train/Control/'\n",
        "        cv2.imwrite(new_dir+str(image_name), result)\n",
        "        time.sleep(2)\n",
        "        cv2.imwrite('./Procesado'+TYPE+'/train/DETR/'+str(image_name), result)\n",
        "        time.sleep(2)\n",
        "\n",
        "        writepredsdetectDict.append({'modelo':MODEL_PATH,\n",
        "                                             'imagen':str(image_name),\n",
        "                                             'set':'Train',\n",
        "                                             'clase':gt_labels,\n",
        "                                             'true_box':true_boxes,\n",
        "                                             'predicion':bbox,\n",
        "                                             'IoU': round(iou[iou_max],3),\n",
        "                                             'etiqueta':labels,\n",
        "                                             'score':round(results['scores'][iou_max].item(),3)\n",
        "                                    })\n",
        "    else:\n",
        "        orig_image=image.copy()\n",
        "        if 'C' in image_name:\n",
        "            new_dir='./data'+TYPE+'/DETR/train/Cncer/'\n",
        "        else:\n",
        "            new_dir='./data'+TYPE+'/DETR/train/Control/'\n",
        "\n",
        "        cv2.imwrite(new_dir+str(image_name), orig_image)\n",
        "        time.sleep(2)\n",
        "        cv2.imwrite('./Procesado'+TYPE+'/train/DETR/'+str(image_name), orig_image)\n",
        "        time.sleep(2)\n",
        "        #-----------we store data---------\n",
        "        writepredsdetectDict.append({'modelo':MODEL_PATH,\n",
        "                                        'imagen':str(image_name),\n",
        "                                        'set':'Train',\n",
        "                                        'clase':gt_labels,\n",
        "                                        'true_box':true_boxes,\n",
        "                                        'predicion':None,\n",
        "                                        'IoU': None,\n",
        "                                        'etiqueta':None,\n",
        "                                        'score':None})\n",
        "print('TRAIN PREDICTIONS COMPLETE')\n",
        "\n",
        "#-------We proceed to store the results in file\n",
        "file_name='resultados.csv'\n",
        "archivo='./data'+TYPE+'/DETR/'+file_name\n",
        "if os.path.isfile(archivo):\n",
        "    modo = 'a+'\n",
        "else:\n",
        "    modo = 'w'\n",
        "with open(archivo, modo, newline='') as csvfile:\n",
        "    fieldnames = ['modelo', 'imagen','set', 'clase','true_box','predicion','IoU','etiqueta','score']\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "    if modo=='w':\n",
        "        writer.writeheader()\n",
        "    for d in writepredsdetectDict:\n",
        "        writer.writerow(d)\n",
        "print('*****END*****')\n",
        "print('Tiempo de ejecucin: ',round((time.time()-inicio)/60,0))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}